import json
import requests
import asyncio
from bs4 import BeautifulSoup
import os
import time
from storage import load_subscriptions
from dotenv import load_dotenv
from telegram import Bot
from telegram.request import HTTPXRequest



# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è .env
load_dotenv()

BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    raise ValueError("‚ùå BOT_TOKEN –Ω–µ –∑–∞–¥–∞–Ω–æ!")

bot = Bot(token=BOT_TOKEN, request=HTTPXRequest())
SENT_FILE = "sent.json"

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∂–µ –æ–±—Ä–æ–±–ª–µ–Ω–∏—Ö event_id
if os.path.exists(SENT_FILE):
    with open(SENT_FILE, "r", encoding="utf-8") as f:
        sent = json.load(f)
else:
    sent = {}

subscriptions = load_subscriptions()

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html",
    "Accept-Language": "uk-UA,uk;q=0.9,en;q=0.8",
    "Referer": "https://sales.ft.org.ua/",
    "Cache-Control": "no-cache",
}

BASE_URL = "https://sales.ft.org.ua/events"

def find_event_ids_by_title(title, pages=5, halls=["chamber", "main"]):
    ids = []
    for hall in halls:
        for page in range(1, pages + 1):
            url = f"{BASE_URL}?page={page}&hall={hall}"
            print(f"    üåê {hall}: {url}")
            resp = requests.get(url, headers=HEADERS)
            soup = BeautifulSoup(resp.text, "html.parser")
            cards = soup.find_all("a", class_="performanceCard")
            for card in cards:
                img = card.find("img")
                alt = img.get("alt", "").strip() if img else ""
                if alt.strip().lower() == title.strip().lower():
                    href = card.get("href", "")
                    if "/events/" in href:
                        event_id = href.split("/")[-1]
                        ids.append(event_id)
    return ids

def check_seats(event_id):
    url = f"https://sales.ft.org.ua/events/{event_id}"
    resp = requests.get(url, headers=HEADERS)
    soup = BeautifulSoup(resp.text, "html.parser")
    seats = soup.select("rect.tooltip-button")
    available = [
        s.get("data-title", "–ë–µ–∑ –Ω–∞–∑–≤–∏") for s in seats
        if "occupied" not in s.get("class", [])
    ]
    return available

async def send_async_message(uid, msg):
    try:
        await bot.send_message(chat_id=uid, text=msg, parse_mode='HTML')
        print(f"üì§ –ù–∞–¥—ñ—Å–ª–∞–Ω–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É {uid}")
    except Exception as e:
        print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –Ω–∞–¥—ñ—Å–ª–∞—Ç–∏ {uid}: {e}")

def notify_users(title, event_id, seats):
    msg = f"üé≠ –ù–æ–≤–∞ –ø–æ–¥—ñ—è '{title}' ‚Äî <b>{len(seats)} –≤—ñ–ª—å–Ω–∏—Ö –º—ñ—Å—Ü—å</b>!\n"
    msg += f"https://sales.ft.org.ua/events/{event_id}\n\n"
    msg += "(–ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ñ –º—ñ—Å—Ü—è –Ω–∞ —Å–∞–π—Ç—ñ)"

    for uid, titles in subscriptions.items():
        if title in titles:
            asyncio.run(send_async_message(uid, msg))

def run_monitor_loop(delay_minutes=1):
    while True:
        print("‚è≥ –ó–∞–ø—É—Å–∫ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É...")

        for title in set(t for subs in subscriptions.values() for t in subs):
            print(f"üîé –ü–µ—Ä–µ–≤—ñ—Ä—è—é: {title}")
            event_ids = find_event_ids_by_title(title)
            print(f"  üîç –ó–Ω–∞–π–¥–µ–Ω–æ {len(event_ids)} ID: {event_ids}")

            sent.setdefault(title, [])
            new_ids = [eid for eid in event_ids if eid not in sent[title]]
            print(f"  üÜï –ù–æ–≤—ñ ID: {new_ids}")

            for eid in new_ids:
                seats = check_seats(eid)
                print(f"    üé´ {eid}: {len(seats)} –≤—ñ–ª—å–Ω–∏—Ö –º—ñ—Å—Ü—å")
                if seats:
                    notify_users(title, eid, seats)
                sent[title].append(eid)

        with open(SENT_FILE, "w", encoding="utf-8") as f:
            json.dump(sent, f, ensure_ascii=False, indent=2)

        print(f"üïí –û—á—ñ–∫—É–≤–∞–Ω–Ω—è {delay_minutes} —Ö–≤...")
        time.sleep(delay_minutes * 60)

if __name__ == "__main__":
    run_monitor_loop(delay_minutes=1)
